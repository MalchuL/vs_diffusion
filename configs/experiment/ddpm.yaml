# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: stylegan/pretrain_stylegan.yaml
  - override /model: ddpm.yaml
  - override /callbacks: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["DPPM"]

seed: 12345

trainer:
  check_val_every_n_epoch: 10
  max_epochs: 400
  limit_train_batches: 800
  limit_val_batches: 10
  log_every_n_steps: 10

datamodule:
  batch_size: ${model.training_config.inner_batch_size}

pretrain_gen: null
task_name: 'DDPM'


